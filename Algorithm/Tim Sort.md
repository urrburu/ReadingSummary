-   **Tim Sort [팀 정렬]**

이번 포스팅의 경우 병합 정렬과 삽입 정렬(그 중 이진 삽입 정렬) 메커니즘을 토대로 하기에 **반드시** [병합(합병) 정렬](https://st-lab.tistory.com/233)과 [이진 삽입 정렬](https://st-lab.tistory.com/262)을 먼저 보고 오시기를 바란다. (참고로 여기서 다룰 병합 정렬은 **Bottom-Up** 방식임에 유의하시기를 바란다.)

팀 정렬은 무엇인지부터 알아보자.

일단 팀 정렬은 Tim Peter 에 의해 고안된 Merge Sort(합병 정렬), Insertion Sort(삽입 정렬)이 혼용 된 하이브리드 정렬 알고리즘이다. 좀 더 자세하게 말하자면, **합병정렬을 기반으로 구현하되, 일정 크기 이하의 부분 리스트에 대해서는 이진 삽입 정렬을 수행**하는 것이다.

무슨 말인가 하면, 대략적으로 이런 느낌이다.

![](https://blog.kakaocdn.net/dn/bR8eeA/btritM49vug/YUVXe5YNKnA5u9jt8if1VK/img.png)

대략적인 모습은 위와 같다.

그러면 왜 퀵 정렬(Quick Sort)처럼 빠른 속도의 정렬이나 병합 정렬처럼 항시 안정적인 O(NlogN)의 정렬 알고리즘들이 있음에도 이러한 두 가지 정렬 알고리즘을 혼용한 정렬들이 나온 것일까?

일단, 이를 이해하기 위해서는 왜 정렬 알고리즘마다 속도의 차이가 나는지를 생각해보아야 한다.

크게 정렬 알고리즘에서 성능을 미치는 원인은 크게 3가지로 볼 수 있다.

1. 비교 및 스왑을 수행하기 위한 반복자(loop) = 반복자가 어떻게 구현되어있는가의 문제

2. 유효 접근 시간 (지역성)

3. 메모리 소비량

(추가적으로 병렬 작업이 가능한가 정도도 될 수 있다)

그럼 하나씩 한 번 살펴보자.

1번의 경우는 우리가 대표적으로 시간복잡도로 측정 되는 기준이 되기 때문에 크게 설명 할 것은 없을 것이다.

2번의 경우에는 아주아주 간단하게 말해서 CPU에서 참조하는 주소를 읽어들이는데 얼마나 소요되는가다. 쉽게 말해 지역성의 원리를 얼마나 잘 따라주냐에 따라 성능이 좌우된다고 보면 된다.

조금 더 구체적으로 말해보자면 이렇다.

캐시는 CPU 칩 안에 들어가는 매우 빠른 메모리라는 건 아마 대부분 알 것이다. 이 캐시 메모리가 중요한 이유는 프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시(Cache)에 자주 참조되는 데이터를 담아두고, 해당 데이터가 필요할 때 메인 메모리 대신 캐시에 접근하도록해 처리 속도를 높인다. (물론 L1, L2, L3 캐시 메모리마다 역할이 조금씩 다른데, 이 부분은 여기서 다룰 내용은 아니니 개괄적으로만 이해하도록 하자)

그러면 캐시를 어떻게 효율적으로 관리하느냐의 문제인데, 결국 캐시에 들어있는 데이터가 얼마나 쓸모있는 데이터가 담겨져 있느냐에 따라 성능이 좌우된다는 것이다. 이를 적중률(Hit-rate)이라고 하는데, 이러한 적중률을 높이기 위한 메커니즘으로는 크게 3가지(혹은 2가지)로 볼 수 있다.

1) 공간 지역성 (군집화(밀도) 정도, 즉, 최근에 접근한 데이터의 주변 공간에 다시 접근하는 경향이 강할 수록 적중률이 높음)

2) 시간 지역성 (최근 접근한 데이터에 다시 접근하는 경향이 높을 수록 적중률이 높음)

3) 순차 지역성 (데이터가 연속적(순차적)으로 접근하려는 경향이 강할 수록 적중률이 높음. 이를 공간 지역성에 포함시키기도 한다)

이 때 우리는 정렬이 목적이지 않는가? 주로 참조되는 때는 비교 및 스왑 과정 일것이다. 이 말은 즉, 결국 같은 비교 및 스왑 횟수를 갖고 있더라도 비교하거나 스왑하는 이벤트 내에서 얼마나 지역성을 만족하는지(요소들이 근처에서 발생하는지)에 따라 성능이 좌우된다는 것이다.

지역성에 대한 예시들 중 대표적으로 행렬 곱의 최적화가 있다. (한 번 검색해서 찾아보시는 것을 강력 추천한다.)

그러면  위에 대한 내용의 연장선상에서 같은 시간 복잡도를 갖는 O(NlogN)의 정렬 알고리즘 중 Heap Sort보다 Quick Sort가 더 빠른지를 설명 할 수 있을 것이다.

Heap Sort는 힙 트리 구조를 활용하기 때문에 부모 혹은 자식 노드를 찾기 위해서는 현재 노드의 절반(1/2) 혹은 두 배씩 이동해야한다. 또한 정렬을 위해 하위 트리부터 루트 트리까지 Heap을 만족하도록 해야하기 때문에 이동하지 않아도 될 불필요한 요소들도 교체될 가능성이 매우 높다.

반면에 Quick Sort(middle pivot 기준)의 경우 피벗을 기준으로 양쪽에서 순차적으로 접근하면서 데이터를 비교하기 때문에 지역성이 높을 뿐더러 교환이 불필요한 요소들을 거의 교환하지 않아 swap비용 자체는 높더라도 교환 횟수의 이점 때문에 평균적으로 성능이 뛰어나다.

-  Heap정렬은 참조 위치가 연속적이거나 인접성을 띄고 있지 않고, 
- Quick 정렬은 한 라운드마다 하나의 피벗을 두고 양쪽에서 순차접근 하는 방식으로 지역성이 높은 것을 볼 수 있다.

그리고 세 번째로 메모리 소비량이다.

Merge Sort의 경우에는 일반적으로 Quick Sort에 비해 30%정도 비교 횟수는 적지만, 새 Buffer을 생성해야 하기 때문에 메모리 접근이 분산 될 수 밖에 없으며 이동 횟수가 많다는 한계점이 있다. 또한 이미 정렬 된 부분 리스트도 탐색하며 쪼개 들어가야하기 때문에 최선의 시간 복잡도 또한 O(NlogN)을 갖는다.

(물론 Scanning 을 통해 O(N)으로도 만들 수 있지만, 여기서는 일반적인 구현에 대해 이야기하도록 하자.)

그렇다고 Merge Sort가 Quick Sort에 비해 항상 성능이 떨어진다는 것은 아니다. 위 Merge Sort의 특성을 거꾸로 생각해본다면 만약 비교비용이 비쌀 경우에는 Merge Sort가 Quick Sort에 비해 빠를 수도 있기 때문이다. 이 말은, 만약 매우 비싼 비교비용을 갖고있는 대용량 데이터에서는 Merge Sort가 성능상 이점을 볼 수도 있다는 의미다.

또한, Quick Sort에서는 해당 포스팅에서도 다뤘지만, 이미 정렬 된 상태에서의 성능은 O(N2)의 시간 복잡도를 갖게 된다는 단점 또한 존재한다.

이러한 이유로 같은 O(NlogN) 시간복잡도를 갖는 정렬알고리즘이어도 정렬 수행시간이 다르게 된다.

그러면 왜 Tim Sort가 필요한지 대략적으로나마 설명 할 수 있다.

Tim Sort가 만들어진 목적을 먼저 말하자면 **현실 데이터들의 종류와 상관 없이 최적으로 정렬을 잘 수행하기 위해서 개발 된 방식**이다.

그래서 Java에서 Arrays.sort 를 통해 정렬 할 때 primitive 1차원 배열 타입의 경우 Quick Sort의 심화 구현인 dual-pivot Quick Sort알고리즘으로 정렬이 되고, primitive 타입이 아닌 객체 타입의 배열을 정렬하게 되면 Tim Sort로 정렬되는 이유가 위와 같은 이유다. (참고로 Collections.sort()의 경우 내부에서 List를 Object 배열로 만들어서 Arrays.sort()로 보낸다.)

그래서 Tim Sort가 뭐야?

즉, 현실 데이터들을 잘 정렬하기 위해 개발 된 **병합 정렬 + 삽입 정렬(그 중 이진 삽입 정렬)을 혼합 한 하이브리드 정렬**이라는 것이다.

위 장단점에서 나왔지만, Quick Sort의 경우 분명 일반적으로 빠르긴 하지만, 특정 상태(정렬 된 상태)에서는 급격히 성능이 떨어지게 된다. 그렇다고 Heap Sort를 쓰자니 지역성이 떨어져 데이터가 얼마나 클지 모르니, 가장 안정적이면서 비교비용이 비쌀 경우에도 이득을 볼 수 있는 병합 정렬이 적절해 보인다.

더군다나 Merge Sort는 안정(stable) 정렬이 가능하기 때문에 현실 데이터에 대해 더욱 알맞은 정렬 방법이기도 하다.

이진 삽입 정렬은 O(N2) 알고리즘임에도 왜 사용되는 것일까? 삽입 정렬의 메커니즘은 각 수행 단계에서 자기가 들어갈 위치를 잡아주게 되는데 구현 자체를 보면 알겠지만, 이미 정렬 된 상태에서는 O(N)의 시간 복잡도를 갖게 된다는 장점과 더불어 **매우 작은 리스트에서는 O(NlogN) 정렬 알고리즘들 못지 않게 매우매우 빠른 정렬 수행 속도를 보이기 때문**이다.

이유야 당연하긴 하지만, 시간 복잡도는 수행 시간의 점근적 성장도를 나타내는 것이다. 그렇기에 정렬해야 할 리스트가 작을 수록 오버헤드가 상당히 작기 때문에 매우 작은 리스트에서는 정렬 수행시간의 비중이 점근적 시간 복잡도보다 오버헤드가 더 크다.

예로들어 Quick Sort의 경우 O(NlogN)의 같은 정렬 알고리즘 중에서도 매우 빠른 정렬 알고리즘이지만 재귀를 사용하기 때문에 매우 작은 리스트에서는 pivot을 기준으로 재귀적 호출을 하는 과정 자체가 추가적인 오버헤드가 발생하기 때문에 삽입정렬에서 리스트를 정렬하는 비용보다 더 커지기도 한다.

그래서 Tim Sort에서는 일정 사이즈의 부분 리스트를 얻고(divide), 각각의 부분리스트들에 대해 삽입정렬을 수행하며 정렬을 하며(sort), 정렬 된 부분리스트들을 다시 합치는 방식(conqure)을 사용하게 된다.

일단, **지역성이 높으면서, 추가적인 메모리를 최소화 하고, 시간복잡도가 O(NlogN) 이하의 알고리즘을 갖을 수 있도록 해야** 정렬이 효율적으로 된다는 건 알았다.

그럼 어떻게 구현해야할지 하나씩 살펴보자.

참고로 이 번 포스팅에서는 처음 보는 개념이 많이 나올 것이다. 최대한 쉽게 설명 해보려고 노력은 하지만, 기본적인 메커니즘을 제대로 이해하지 못한다면 어려울 수 밖에 없으니, 만약 이해가 안된다면 언제든 댓글로 남겨주시기를 바란다.

또한 이전처럼 원소를 하나하나 이미지로 이동하는 과정을 그릴 수는 없다. 그렇기 때문에 이 번 포스팅에서 올라가는 이미지들은 대체로 추상적일 것이다. 이 점 유의하시기를 바란다.

그리고 자바에서 제공하는 Tim Sort의 경우 사소한 것 까지 최적화가 되어있다. 하지만, 이러한 사소한 부분까지 다 다루려고 하면 오히려 Tim Sort의 메커니즘을 이해하는데 방해가 될 것 같아서 **크게 중요한 것들 위주로만 구현을 할 예정**이다.